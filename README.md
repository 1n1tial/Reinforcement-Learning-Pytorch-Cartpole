# PyTorch CartPole Example
Simple Cartpole example writed with pytorch.

## Why Cartpole?
Cartpole is very easy problem and is converged very fast in many case.
So you can run this example in your computer(maybe it take just only 1~2 minitue).

## Rainbow
- [x] DQN [[1]](#reference)
- [x] Double [[2]](#reference)
- [x] Duel [[3]](#reference)
- [x] Multi-step [[4]](#reference)
- [x] PER(Prioritized Experience Replay) [[5]](#reference)
- [x] Nosiy-Net [[6]](#reference)
- [x] Distributional(C51) [[7]](#reference)
- [x] Rainbow [[8]](#reference)

## PG
- [x] REINFORCE [[9]](#reference)
- [x] Actor Critic [[10]](#reference)
- [x] Advantage Actor Critic
- [x] GAE(Generalized Advantage Estimation) [[12]](#reference)
- [ ] TRPO [[13]](#reference)
- [ ] PPO [[14]](#reference)

## Parallel
- [ ] A3C (Asynchronous Advange Actor Critice) [[11]](#reference)

## Distributional
- [ ] QRDQN

## Will
- [ ] RND
- [ ] APE-X
- [ ] R2D2


## Reference
[1] [Playing Atari with Deep Reinforcement Learning](http://arxiv.org/abs/1312.5602)  
[2] [Deep Reinforcement Learning with Double Q-learning](http://arxiv.org/abs/1509.06461)  
[3] [Dueling Network Architectures for Deep Reinforcement Learning](http://arxiv.org/abs/1511.06581)  
[4] [Reinforcement Learning: An Introduction](http://www.incompleteideas.net/sutton/book/ebook/the-book.html)  
[5] [Prioritized Experience Replay](http://arxiv.org/abs/1511.05952)  
[6] [Noisy Networks for Exploration](https://arxiv.org/abs/1706.10295)  
[7] [A Distributional Perspective on Reinforcement Learning](https://arxiv.org/abs/1707.06887)  
[8] [Rainbow: Combining Improvements in Deep Reinforcement Learning](https://arxiv.org/abs/1710.02298)  
[9] [Policy Gradient Methods for Reinforcement Learning with Function Approximation ](https://papers.nips.cc/paper/1713-policy-gradient-methods-for-reinforcement-learning-with-function-approximation.pdf)
[10] [Actor-Critic Algorithms](https://papers.nips.cc/paper/1786-actor-critic-algorithms.pdf)
[11] [Asynchronous Methods for Deep Reinforcement Learning](https://arxiv.org/pdf/1602.01783.pdf)
[12] [HIGH-DIMENSIONAL CONTINUOUS CONTROL USING GENERALIZED ADVANTAGE ESTIMATION](https://arxiv.org/pdf/1506.02438.pdf)
[13] [Trust Region Policy Optimization](https://arxiv.org/pdf/1502.05477.pdf)
[14] [Proximal Policy Optimization](https://arxiv.org/pdf/1707.06347.pdf)
